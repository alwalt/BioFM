{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcec35b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 387140])\n"
     ]
    }
   ],
   "source": [
    "# Load the edge index tensor that was extracted from KNN\n",
    "# edge_index has shape [2, num_edges] where:\n",
    "#   - edge_index[0] = source node indices\n",
    "#   - edge_index[1] = target node indices\n",
    "import torch\n",
    "\n",
    "edge_index = torch.load(\"./graph/edge_index_top20.pt\")\n",
    "print(edge_index.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254aa3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize node features for the graph\n",
    "# num_genes = total number of unique genes in the KNN edge_index\n",
    "# We create random embeddings of size [num_genes, d_model] to simulate gene embeddings\n",
    "num_genes = edge_index.max().item() + 1\n",
    "d_model = 128   # small for testing\n",
    "\n",
    "# x shape: [num_genes, d_model] - each gene gets a random feature vector\n",
    "x = torch.randn(num_genes, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7bed5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/walt/miniconda3/envs/esm2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Define a Graph Attention Network (GAT) with 2 layers\n",
    "# GATv2Conv uses multi-head attention to aggregate information from neighboring nodes\n",
    "# heads=4: use 4 attention heads for richer representational capacity\n",
    "# concat=False: average the heads instead of concatenating (keeps dimensions constant)\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "\n",
    "class GeneGAT(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        # First GAT layer: applies attention over KNN edges, outputs [num_genes, dim]\n",
    "        self.gat1 = GATv2Conv(dim, dim, heads=4, concat=False)\n",
    "        # Second GAT layer: further refines embeddings with attention, outputs [num_genes, dim]\n",
    "        self.gat2 = GATv2Conv(dim, dim, heads=4, concat=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Layer 1: attend to neighbors, apply ReLU activation\n",
    "        x = self.gat1(x, edge_index).relu()\n",
    "        # Layer 2: attend to neighbors again on refined features\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c522acdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19357, 128]) → torch.Size([19357, 128])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the GAT model and run a forward pass\n",
    "# This tests whether the KNN-extracted edges work correctly with the GATv2 layers\n",
    "model = GeneGAT(d_model)\n",
    "out = model(x, edge_index)\n",
    "\n",
    "# Verify that input and output have the same shape\n",
    "# (GAT preserves node count, only refines feature representations)\n",
    "print(x.shape, \"→\", out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db4cee4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['embeddings', 'genes', 'model'])\n"
     ]
    }
   ],
   "source": [
    "esm2_raw = torch.load(\"./data/embeddings/esm2_t6_8M_UR50D_gene_embeddings.pt\")\n",
    "print(type(esm2_raw))\n",
    "print(esm2_raw.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29678977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATA] Loading ESM2 protein embeddings...\n",
      "  ✓ ESM2 embeddings: torch.Size([19357, 320])\n",
      "  ✓ ESM2 gene count: 19357\n",
      "  ✓ ESM2 embeddings: torch.Size([19357, 320])\n",
      "  ✓ ESM2 gene count: 19357\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[DATA] Loading ESM2 protein embeddings...\")\n",
    "raw = torch.load(\"./data/embeddings/esm2_t6_8M_UR50D_gene_embeddings.pt\")\n",
    "\n",
    "esm2 = raw[\"embeddings\"].float()     # main embedding matrix\n",
    "esm2_genes = raw[\"genes\"]            # list of gene names for ordering\n",
    "\n",
    "print(\"  ✓ ESM2 embeddings:\", esm2.shape)\n",
    "print(\"  ✓ ESM2 gene count:\", len(esm2_genes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "449e13d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MT-ND1', 'MT-ND2', 'MT-CO1', 'MT-CO2', 'MT-ATP8', 'MT-ATP6', 'MT-CO3', 'MT-ND3', 'MT-ND4L', 'MT-ND4']\n",
      "['MT-ND1', 'MT-ND2', 'MT-CO1', 'MT-CO2', 'MT-ATP8', 'MT-ATP6', 'MT-CO3', 'MT-ND3', 'MT-ND4L', 'MT-ND4']\n",
      "19357\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "archs4_genes = pd.read_csv(\n",
    "    \"./data/archs4/processed_short_proteins/train_gene_order_short.csv\"\n",
    ")[\"gene_symbol\"].tolist()\n",
    "\n",
    "print(esm2_genes[:10])\n",
    "print(archs4_genes[:10])\n",
    "print(len(set(esm2_genes) & set(archs4_genes)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "336ab011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM2 shape: torch.Size([19357, 320])\n",
      "Embedding for gene index 0:\n",
      "tensor([ 9.2978e-02,  6.5294e-02,  1.0580e-01,  1.7076e-01,  2.4781e-01,\n",
      "        -1.1651e-01,  1.5424e-01,  1.3710e-02,  3.6349e-02, -2.3073e-01,\n",
      "         1.5996e-01, -6.3580e-02, -1.9081e-02,  1.7054e-01,  2.7768e-01,\n",
      "        -2.0805e-01,  5.3693e-02,  9.7801e-02, -7.7328e-02,  1.6150e-01,\n",
      "         6.6416e-02,  4.3377e-02,  1.2056e-01,  5.8363e-02,  1.8182e-01,\n",
      "         1.6818e-01, -5.2231e-02, -4.0707e-02,  2.4665e-01,  2.2673e-01,\n",
      "        -2.4801e-02, -2.1880e-01,  7.9713e-02,  1.3767e-01,  2.4228e-01,\n",
      "        -1.8152e-01,  1.5154e-01,  2.8462e-02,  1.5701e-01,  1.9493e-01,\n",
      "        -6.5894e-02, -1.6705e-02,  1.0056e-01,  2.9792e-01,  7.9673e-03,\n",
      "        -5.8195e-03, -7.1435e-01,  1.1258e-01,  1.3825e-01, -1.4130e-01,\n",
      "        -1.1186e-01,  2.9676e-03, -4.3466e-02,  1.5705e-01, -2.6676e-02,\n",
      "        -3.0482e-01,  7.9775e-02, -1.0222e-01, -1.2259e-01,  3.7344e-02,\n",
      "        -5.3718e-02, -2.8479e-02, -5.1508e+00, -3.5766e-02, -1.7012e-02,\n",
      "        -5.0310e-02,  2.8096e-01,  2.0862e-01, -3.3473e-01,  1.2741e-01,\n",
      "        -1.7101e-01, -2.2169e-02, -1.7125e-02,  1.2081e-01, -1.5740e-02,\n",
      "         9.0786e-02, -4.3509e-02,  1.3961e-01,  8.1158e-02, -2.1631e-01,\n",
      "         3.4652e-02,  5.9722e-02, -6.5879e-03,  3.3136e-02, -4.0943e-02,\n",
      "        -8.7527e-02, -4.8964e-02, -1.2498e-01, -1.1259e-01, -5.7336e-02,\n",
      "        -2.0814e-01,  4.1831e-02,  7.6753e-03,  1.4489e-01, -1.1950e-01,\n",
      "         1.2625e-01, -2.0319e-01, -7.8944e-02, -5.4772e-02,  6.4643e-02,\n",
      "        -1.3289e-02,  3.2674e-02, -1.8541e-01,  2.1069e-02,  8.1546e-02,\n",
      "         1.1946e-01,  1.1981e-01, -4.9287e-02, -1.4316e-01, -9.7112e-02,\n",
      "         2.2803e-03,  1.2994e-01, -2.0441e-02, -1.1091e-02, -5.7007e-02,\n",
      "         9.9846e-02, -1.3590e-01,  5.9199e-02, -1.3114e-01, -1.3278e-01,\n",
      "         1.1941e-01,  9.3229e-02,  8.9765e-02, -4.5521e-02,  4.3342e-02,\n",
      "         1.5300e-01,  6.6688e-02, -5.9000e-02, -2.5599e-01,  1.1924e-01,\n",
      "         1.8125e-01,  4.5679e-03,  2.2317e-01,  1.3017e-01,  3.4739e-01,\n",
      "        -2.9167e-01, -1.7333e-01,  1.8943e-02,  5.6240e-02,  1.7779e-02,\n",
      "         1.1264e-01, -2.6707e-01, -6.1107e-02, -2.2091e-01,  6.6255e-02,\n",
      "         1.5754e-01, -8.7014e-03,  2.1968e-01, -1.2950e-01,  2.6053e-01,\n",
      "        -2.0016e-02, -3.4915e-02, -3.9636e-01, -3.0633e-01,  1.7839e-01,\n",
      "         1.6181e-02,  6.3643e-02,  2.1031e-03,  1.1475e-01, -5.9773e-02,\n",
      "        -7.4903e-02,  1.7224e-01,  1.3560e-01, -5.9411e-02, -1.3517e-02,\n",
      "        -3.4191e-01,  4.6476e-02, -1.3840e-01,  7.1409e-02,  1.5069e-01,\n",
      "         7.6269e-02,  1.1874e-01,  7.3854e-02, -2.0085e-02,  1.4986e-02,\n",
      "         2.0433e-01,  1.6295e-01,  4.0803e-02,  5.6299e-03, -4.6920e-02,\n",
      "         1.7518e-01, -2.4264e-01, -1.9825e-02, -9.3969e-02, -1.5541e-01,\n",
      "         7.9981e-03, -2.4836e-02,  4.5207e-02,  1.2551e-02, -9.0799e-02,\n",
      "         5.9827e-02,  1.4676e-01,  1.2095e-01,  1.0790e-01, -1.8018e-02,\n",
      "         5.0004e-02,  8.5139e-02, -7.1214e-02,  6.8265e-02,  2.4194e-01,\n",
      "         3.8021e-02,  8.5944e-02,  4.3775e-01, -2.7094e-02, -1.5326e-01,\n",
      "        -7.0249e-02, -2.3851e-01,  4.3990e-02, -1.5232e-02,  2.6633e-02,\n",
      "         1.5274e-01, -1.7385e-01,  2.4212e-03,  3.3871e-02,  2.1777e-01,\n",
      "        -1.3122e-01,  8.5330e-02,  7.4941e-02, -5.3949e-02, -7.4648e-02,\n",
      "        -7.8343e-02,  2.1450e-01,  1.4385e-01,  1.6503e-02,  2.1238e-01,\n",
      "         1.1086e-01, -1.2092e-01,  9.7558e-03, -1.7240e-02,  8.7946e-03,\n",
      "        -5.1071e-03, -1.7087e-02,  1.0533e-01, -7.7337e-02,  1.3154e-01,\n",
      "        -4.9960e-02,  1.0178e-01,  2.0168e-02,  1.2524e-01, -4.0303e-02,\n",
      "        -2.5418e-01, -1.1343e-01, -9.4720e-02,  3.8394e-02, -3.3017e-02,\n",
      "         3.8760e-03,  4.0270e-01, -8.8748e-02,  2.2002e-01, -3.0343e-02,\n",
      "         6.9015e-02, -1.9817e-01, -2.5703e-03, -1.2100e-01,  7.0130e-02,\n",
      "         1.3563e-01,  1.1318e-01,  3.3194e-02, -1.6209e-01, -1.2779e-01,\n",
      "        -4.3499e-02, -1.9272e-01,  9.4646e-04, -1.7026e-01,  4.4417e-02,\n",
      "         6.8239e-02, -1.4721e-01, -2.8760e-01, -1.6237e-01, -1.2629e-01,\n",
      "        -1.6172e-01, -2.8203e-02, -7.8499e-03,  6.8582e-03, -3.3070e-02,\n",
      "        -6.5075e-02,  1.4611e-02, -2.1629e-01,  1.2388e-01, -2.3562e-01,\n",
      "        -3.7731e-02, -1.6463e-01,  1.4291e-01, -9.7960e-02,  3.5662e-01,\n",
      "         1.2423e-01, -2.0850e-01, -1.3478e-01,  2.4776e-01, -3.5112e-02,\n",
      "        -2.3898e-01, -2.4521e-02,  3.6824e-01, -3.0487e-02,  1.1258e-01,\n",
      "        -1.1424e-01, -1.4537e-01,  8.2407e-02,  1.0098e-02,  5.1659e-02,\n",
      "        -5.5582e-02, -1.1629e-01,  9.7615e-03,  5.5265e-02,  1.2211e-01,\n",
      "        -5.1844e-02, -1.6452e-01,  8.5078e-02, -3.3831e-01, -6.3552e-02,\n",
      "        -9.0628e-03,  1.6414e-01, -8.2756e-02,  4.5074e-02,  1.3035e-01,\n",
      "         8.1812e-02,  5.6722e-02,  2.1070e-02, -1.1520e-01,  1.2604e-01])\n",
      "Vector shape: torch.Size([320])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load file\n",
    "path = \"./data/embeddings/esm2_t6_8M_UR50D_gene_embeddings.pt\"\n",
    "data = torch.load(path)\n",
    "\n",
    "# Extract embeddings\n",
    "esm2 = data[\"embeddings\"]        # tensor [19357, 320]\n",
    "\n",
    "print(\"ESM2 shape:\", esm2.shape)\n",
    "\n",
    "# Pick a gene index (for example: gene 0)\n",
    "idx = 0\n",
    "vec = esm2[idx]\n",
    "\n",
    "print(f\"Embedding for gene index {idx}:\")\n",
    "print(vec)\n",
    "print(\"Vector shape:\", vec.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05f649a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (19357, 9446)\n",
      "Index length (rows): 19357\n",
      "Column length (genes): 9446\n"
     ]
    }
   ],
   "source": [
    "X_df = pd.read_parquet(\"./data/archs4/processed_short_proteins/test_expr_logtpm_short.parquet\")\n",
    "print(\"Shape:\", X_df.shape)\n",
    "print(\"Index length (rows):\", len(X_df.index))\n",
    "print(\"Column length (genes):\", len(X_df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48053d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2803a2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
