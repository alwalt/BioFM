{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcec35b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 387140])\n"
     ]
    }
   ],
   "source": [
    "# Load the edge index tensor that was extracted from KNN\n",
    "# edge_index has shape [2, num_edges] where:\n",
    "#   - edge_index[0] = source node indices\n",
    "#   - edge_index[1] = target node indices\n",
    "import torch\n",
    "\n",
    "edge_index = torch.load(\"./graph/edge_index_top20.pt\")\n",
    "print(edge_index.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254aa3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize node features for the graph\n",
    "# num_genes = total number of unique genes in the KNN edge_index\n",
    "# We create random embeddings of size [num_genes, d_model] to simulate gene embeddings\n",
    "num_genes = edge_index.max().item() + 1\n",
    "d_model = 128   # small for testing\n",
    "\n",
    "# x shape: [num_genes, d_model] - each gene gets a random feature vector\n",
    "x = torch.randn(num_genes, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7bed5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/walt/miniconda3/envs/esm2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Define a Graph Attention Network (GAT) with 2 layers\n",
    "# GATv2Conv uses multi-head attention to aggregate information from neighboring nodes\n",
    "# heads=4: use 4 attention heads for richer representational capacity\n",
    "# concat=False: average the heads instead of concatenating (keeps dimensions constant)\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "\n",
    "class GeneGAT(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        # First GAT layer: applies attention over KNN edges, outputs [num_genes, dim]\n",
    "        self.gat1 = GATv2Conv(dim, dim, heads=4, concat=False)\n",
    "        # Second GAT layer: further refines embeddings with attention, outputs [num_genes, dim]\n",
    "        self.gat2 = GATv2Conv(dim, dim, heads=4, concat=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Layer 1: attend to neighbors, apply ReLU activation\n",
    "        x = self.gat1(x, edge_index).relu()\n",
    "        # Layer 2: attend to neighbors again on refined features\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c522acdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19357, 128]) → torch.Size([19357, 128])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the GAT model and run a forward pass\n",
    "# This tests whether the KNN-extracted edges work correctly with the GATv2 layers\n",
    "model = GeneGAT(d_model)\n",
    "out = model(x, edge_index)\n",
    "\n",
    "# Verify that input and output have the same shape\n",
    "# (GAT preserves node count, only refines feature representations)\n",
    "print(x.shape, \"→\", out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4cee4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
